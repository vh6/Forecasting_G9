# 3. Exploratory data analysis

```{r, echo = FALSE, message = FALSE}
(here::here("scripts/setup.R"))
```

## 3.1 Real Estate

In our exploratory data analysis (EDA) on real estate data in France spanning the years 2014 to 2021, we aim to generate meaningful visualizations that shed light on the dynamics within this dataset. Beyond internal real estate factors such as transaction numbers, property types, and pricing trends, we intend to integrate external variables like criminality rates, interest rates, unemployment rates, and population statistics. By incorporating these additional dimensions, we seek a comprehensive understanding of how real estate trends align or diverge in relation to broader socio-economic indicators. Through the creation of informative graphs, we aspire to visually represent and analyze the interplay between real estate dynamics and various external factors over the specified time period, facilitating a more nuanced interpretation of the dataset for our class project.

#### Population range 

In our analysis, we collectively categorized the population into four layers  Low, Moderate, High, and Very High—based on quartiles. This segmentation allows us to explore how population size influences variables like crime rates, unemployment, and property prices. By aggregating data and calculating average values for each layer, we gain insights into the unique impact of population size on these factors. Visualizing these relationships through plots helps us identify trends across different population layers.

```{r, echo = TRUE, message = FALSE}
# Load required libraries
PrixPopCrimeYearChomInt_vf <- read_csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomInt_vf.csv")

library(dplyr)

# Calculate summary statistics for population across all departments
summary_population <- PrixPopCrimeYearChomInt_vf %>%
  summarise(
    Min_POP = min(POP),
    Q25_POP = quantile(POP, 0.25),
    Median_POP = median(POP),
    Q75_POP = quantile(POP, 0.75),
    Max_POP = max(POP)
  )

summary_table <- summary_population %>%
  kable("html") %>%
  kable_styling(full_width = FALSE)

summary_table

```

### 3.1.1 Dwelling Transactions: Mutations

```{r,echo = TRUE}

mainXpop2 <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")

# Create a table for DEPARTEMENT with less than 400 unique values
departement_table <- mainXpop2 %>%
  count(DEPARTEMENT, PLACE) %>%  # Include the PLACE column in the count
  filter(n < 400) %>%
  gt() %>%
  fmt_number(columns = c(n), decimals = 0)  # Optional: Format the 'n' column

# Print the table
departement_table
```
The table below highlights instances in the dataset where a department contains fewer than 400 unique values, potentially leading to non-significant data points.

```{r, echo = TRUE, warning = FALSE}

mainXpop2 <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")
                      
# Créez les tranches
tranches <- c(0, 5 , 10 , 50, 100, 1000, Inf)

# Ajoutez une nouvelle colonne "Tranches" à votre dataframe
mainXpop2$Tranches <- cut(mainXpop2$Nb_mutations, breaks = tranches, labels = c("0-5","6-10", "11-50", "51-100", "101-1000", "1000+"), include.lowest = TRUE)

# Créez un histogramme
histogram <- table(mainXpop2$Tranches)

# Désactiver la notation scientifique pour l'axe y
options(scipen = 999)

# Dessinez l'histogramme avec l'axe y en notation décimale
barplot(histogram, mainXpop2 = "Histogram of Nb_mutations per group", xlab = "Group", ylab = "Frequency", col = "orange", border = "black")
```
This code segment categorizes the number of sales in property and house transactions into specific ranges or "tranches" to better understand the distribution of sales counts. The purpose is to address potential skewness in the data and gain insights into transaction frequency patterns. By creating a categorical variable and visualizing the data through a histogram, the analysis aims to discern patterns in transaction frequency and improve the accuracy of insights, especially when dealing with very low mutation values that occur more frequently. This approach recognizes the importance of considering transaction frequency when computing averages to provide more reliable insights into real estate dynamics.

#### Transactions by type of good 

```{r, echo = TRUE}

dataset <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/dataset.csv")

# Aggregate the data by year
aggregated_data <- aggregate(cbind(NbMaisons_total, NbApparts_total) ~ Annee, data = dataset, sum)

# Transform the data into long format
aggregated_data_long <- gather(aggregated_data, key = "Type", value = "Total", -Annee)

# Create a ggplot2 chart
p <- ggplot(aggregated_data_long, aes(x = Annee, y = Total, fill = Type)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
  geom_line(aes(x = Annee, y = Total, group = Type, color = Type), linetype = "dashed", size = 1) +
  labs(title = "Total number of house and apartment sales per year",
       y = "Total number of sales",
       x = "Year") +
  scale_fill_manual(values = c("NbMaisons_total" = "blue", "NbApparts_total" = "red")) +
  scale_color_manual(values = c("NbMaisons_total" = "blue", "NbApparts_total" = "red")) +
  theme_minimal()

# Convert ggplot2 chart to plotly
p_plotly <- ggplotly(p, height = 400, width = 750)

p_plotly <- p_plotly %>%
  layout(
    title = list(text = "Total number of house and apartment sales per year", font = list(size = 14)),
    margin = list(l = 50, r = 50, b = 50, t = 80)
  )

# Display the interactive plot
p_plotly
```

This graphic presents a comprehensive overview of housing and apartment sales from 2014 to 2021, categorizing the data by transaction volume per year. The resulting bar chart reveals a general upward trend in sales, with an interesting peak in the mid-years. However, there is a noticeable variation in 2017 where the sales volume unexpectedly dips. This trend suggests potential market trends or economic factors such as interest rate changes, policy adjustments, or shifts in buyer sentiment, prompting a deeper look into market dynamics, financial influences, and regulatory impacts. The objective of this code-driven analysis is to uncover the driving forces behind the transaction volumes, providing a clearer picture of the real estate market's health and direction, and identifying any cyclical patterns or irregularities that could inform future market predictions and investment strategies.

#### Transactions by group 

```{r, echo = TRUE, message = FALSE, out.width='100%'}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
new_data <- data %>%
  group_by(Year, Group) %>%
  summarise(house = sum(NbHouses), appart = sum(NbApparts))

# Reshape the data for plotting
plot_data <- tidyr::gather(new_data, key = "Type", value = "Count", -Year, -Group)

# Plotting the number of houses and apartments for each year, group, and type
ggplot(plot_data, aes(x = Year, y = Count, fill = Type)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_line(aes(group = Type, linetype = Type), position = position_dodge(0.9), size = 0.9) +
  scale_linetype_manual(values = c("solid", "dashed")) +  # Set line types
  facet_wrap(~Group) +  # Separate bars by group
  labs(title = "Houses and Apartments sales per Year by Group",
       x = "Year",
       y = "Count",
       fill = "Type") +
  theme_minimal()
```
The data plot reveals a consistent uptick in annual sales across all groups, with a minor dip in 2017, potentially tied to macroeconomic factors. Notably, groups 1 to 3, characterized by lower population density, show a higher prevalence of house sales. Conversely, in the urban setting of group 4, there is a distinct rise in apartment transactions, aligning with expectations. This concise analysis not only underscores the overall positive sales trend but also sheds light on the dominant property types in different demographic settings, offering valuable insights into the real estate dynamics of each group.


### 3.1.2 Average Price Observations

```{r, echo = TRUE}

PrixPopCrimeYearChomInt_vf <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

library(ggplot2)
library(dplyr)

# Calculate the average Prixm2Moyen per year
average_prices <- PrixPopCrimeYearChomInt_vf %>%
  group_by(Annee) %>%
  summarise(Avg_Prixm2Moyen = mean(Prixm2Moyen))

# Plot the average Prixm2Moyen per year with filled area under the curve
ggplot(average_prices, aes(x = Annee, y = Avg_Prixm2Moyen)) +
  geom_line() +
  labs(title = "Average Prixm2Moyen per Year",
       x = "Year",
       y = "Average Prixm2Moyen")
```
This plot shows the average price per square meter of real estate from 2014 to 2021. The line graph illustrates a significant increase in prices, especially noticeable after 2018. This steep upward trend in the average price indicates a robust growth in the real estate market, potentially reflecting factors such as increased demand, economic growth, or a reduction in supply.  

#### Average Price per group 

```{r, echo = TRUE, message = FALSE}
#breaks = c(0, 250000, 500000, 800000, 3000000),
#labels = c("Group 1", "Group 2", "Group 3", "Group 4"))

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

new_data <- data %>%
  group_by(Year, Group) %>%
  summarise(avg_Prixm2Moyen = mean(AvgSQmeter))

# Plotting the average Prixm2Moyen in terms of year by group
ggplot(new_data, aes(x = Year, y = avg_Prixm2Moyen, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Avg Price/m² by Group",
       x = "Year",
       y = "Price/m²",
       color = "Group") +
  theme_minimal()
```
On this graph we can see the price trends for the different groups selected earlier. Group 4 stands out for its high prices, but we can also see that all the groups have been growing since 2014. We can therefore say that the real estate market in France has been growing overall since 2014, except for a slight decline in rural areas in 2016.

#### Histogram price frequency 

```{r, echo = TRUE}
#TOTAL average price m2
mainXpop2 <- read_csv("~/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")
hist(mainXpop2$Prixm2Moyen, main = "Average Price/m2", col = "pink", xlab = "Average Price", xlim = c(0, 8000))
```
This histogram illustrating the distribution of the total average price per square meter (**`AveragePrice/m2`**) in the dataset. The visualization offers insights into the variation and frequency of average prices per square meter within the specified range, contributing to the broader exploration of real estate market dynamics in France.

#### Price frequency Curve 

```{r, echo = TRUE, fig.width=15, fig.height=9}

mainXpop2 <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")
                      
#TOTAL average price m2/ year 
ggplot(mainXpop2, aes(x = Prixm2Moyen)) +
  geom_histogram(binwidth = 100, position = "identity", alpha = 0.7, fill = "blue") +
  labs(title = "Histogram of AveragePricem2",
       x = "AvPricem2",
       y = "Frequency") +
  facet_wrap(~Annee, scales = "free",  ncol = 4) +
  theme_minimal()+
  scale_x_continuous(labels = scales::comma_format(scale = 1e-3, suffix = "k")) +
  coord_cartesian(xlim = c(0, 8000))
```
The depicted left-skewed trend and consistent pattern over the years remain evident in the distribution of the average price per square meter (**`Prixm2Moyen`**). The increasing frequency of prices exceeding the average in both total average price and price per square meter suggests a cohesive upward trajectory in real estate values throughout the specified time period, emphasizing a linked relationship between the two metrics.

#### Box and Whisker Plot: Price Distribution by Department

```{r, echo = TRUE}

# Boxplot for Price Distribution by Department with adjusted aspect ratio
#boxplot(Prixm2Moyen ~ DEPARTEMENT, data = main, col = "skyblue", 
# main = "Price/m2 Distribution by Department")
```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Groupe-AI/plot1.png){width=800}
In examining the data by department, noticeable outliers are evident, suggesting instances of exaggeration, likely influenced by unique values in certain departments or even specific communes. At this juncture, opting for the median over the mean proves more insightful due to its robustness in handling extreme values.


#### Scatter: Price in terms of Surface 

```{r, echo = TRUE, message = FALSE}

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

#new_data <- data %>%
#  group_by(Annee, DEPARTEMENT) %>%
#  summarise(avgSurface = mean(SurfaceMoy), Prixm2Moyen = mean(Prixm2Moyen))

#ggplot(new_data, aes(x = avgSurface, y = Prixm2Moyen, color = as.factor(Annee))) +
# geom_point() +
# geom_smooth(method = "lm", se = FALSE, size = 0.8) +  # Add regression line
# facet_wrap(~Annee, scales = "free", ncol = 2) +  # 2 columns in each row
# labs(title = "Scatter Plot: Prixm2Moyen vs avgSurface",
#     x = "avgSurface",
#      y = "Prixm2Moyen",
#     color = "Year") +
# theme_minimal()

```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/scatter_surface.png)
This scatterplot illustrates the relationship between the average surface area (**`SurfaceMoy`**) and the average price per square meter (**`Prixm2Moyen`**). The negative slope of the added regression line (abline) indicates an inverse correlation: as the surface area increases, the average price per square meter tends to decrease. This suggests a potential trend where larger properties have a lower price per square meter compared to smaller ones, providing valuable insights into the pricing dynamics within the dataset. The inclusion of the regression line enhances the visualization by highlighting this negative correlation trend.

#### Scatter: Price in terms of Surface by Group

```{r, echo = TRUE}
# data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
# 
# new_data <- data %>%
#   group_by(Annee, DEPARTEMENT, Group) %>%
#   summarise(avgSurface = mean(SurfaceMoy), Prixm2Moyen = mean(Prixm2Moyen))
# 
# library(ggplot2)
# 
# # Assuming your data frame is named new_data
# # Create the scatter plot with regression line for each year and each group
# plot <- ggplot(new_data, aes(x = avgSurface, y = Prixm2Moyen, color = Group)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE) +  # Add regression line without confidence interval
#   facet_wrap(~Annee, ncol = 2) +  # Facet by year
#   labs(title = "Scatter Plot and Regression Lines by Group",
#        x = "Average Surface",
#        y = "Prixm2Moyen") +
#   theme_minimal()+
#   xlim(85, 115) +  # Set x-axis limits
#   ylim(800, 3500)  # Set y-axis limits
# 
# # Show the plot
# print(plot)

```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/scatter_by_group.png)
After segregating the data by population groups (low, average, high, very high), a distinct pattern emerges. It becomes evident that in the most densely populated areas in France, there is a tendency for larger properties to exhibit lower prices per square meter. On the contrary, in rural environments, this trend is less pronounced, and in some instances, it even reverses, indicating a potential inversion of the relationship between property size and price in less densely populated regions.

#### Yearly Real estate average price in France

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Main /main.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate map for a specific year
generate_map <- function(year) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year
  moyenne_prix_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(moyenne_prix_m2 = mean(Prixm2Moyen))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, moyenne_prix_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = moyenne_prix_m2), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = "Moyenne\nPrix/m2",
      option = "magma",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Moyenne du Prix au mètre carré par Département en", year))
}

# Generate maps for the years 2014 to 2021
for (year in 2014:2021) {
  map <- generate_map(year)
}
```

In this R code, the objective is to conduct a geospatial analysis to visualize and understand the spatial distribution of average real estate prices per square meter across different departments in France from 2014 to 2021. The code involves reading a primary dataset containing relevant real estate information, including the average prices. It then utilizes geographical data in a GeoJSON file outlining the boundaries of French departments. For each year in the range 2014 to 2021, the code filters and aggregates the data, creating thematic maps using **`ggplot2`** and **`sf`**. These maps use color gradients to represent the variation in average prices, with the **`viridis`** package providing a visually appealing color scale. Finally, the maps are saved as PNG images, enabling a comprehensive visual exploration of how real estate prices have evolved across different regions of France over the specified time period.

::: {.nav-pills}
::: {.panel-tabset}

## 2014
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2014.png)

## 2015
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2015.png)

## 2016
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2016.png)

## 2017
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2017.png)

## 2018
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2018.png)

## 2019
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2019.png)

## 2020
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2020.png)

## 2021
![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2021.png)
:::
:::

The script then iterates through the years 2014 to 2021, generating maps for each year and saving them as PNG files. The maps visually represent the average real estate prices per square meter in French departments, with color-coded regions indicating varying price levels. The use of libraries like sf, dplyr, and ggplot2 streamlines spatial data handling and visualization, making the code concise and effective for creating a series of informative maps over multiple years. Additionally, the use of loops and functions enhances code reusability and readability.

Observing the real estate market dynamics during the COVID period, a noteworthy pattern emerges, revealing an upward trend in prices along the coastline and in rural areas. This shift implies a growing preference among individuals to move away from urban centers, possibly influenced by changing lifestyle preferences and a heightened appreciation for more spacious and serene environments. The increased demand in these locations could be a reflection of a broader societal trend driven by the pandemic, where individuals seek homes in areas offering tranquility and proximity to nature, contributing to the observed price surge in coastal and rural real estate markets.

## 3.2 Criminality in France

#### Crime rate over the years 

```{r, echo = TRUE, message = FALSE, warning = FALSE }

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts))

# Create a new column named 'criminality' as crimes per 1000 population
new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

# Create a plot of crime rate over the years
crime_plot <- ggplot(new_data, aes(x = Year, y = criminality)) +
  geom_line() +
  geom_point() +
  labs(title = "Crime Rate Over the Years",
       x = "Year",
       y = "Crime Rate per ‰") +
  theme_minimal()

# Show the plot
print(crime_plot)
```
In our real estate project in France, we are examining various socio-demographic factors, including the analysis of crime rates in France from 2016 to 2021. Initially, we hypothesized that higher crime rates might be associated with lower-cost housing. However, upon closer inspection, we observed a correlation indicating that in major cities like Paris, the crime rate tends to increase with population density.

#### Crime rate over the years by group 

```{r, echo = TRUE, message = FALSE, warning = FALSE }

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

new_data <- filtered_data %>%
  group_by(Year, Group) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)


ggplot(new_data, aes(x = Year, y = criminality, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Avg Crime rate by Group",
       x = "Year",
       y = "Crime rate",
       color = "Group") +
  theme_minimal()
```
This observation aligns with the logical expectation that more populated areas are likely to have higher chances of criminal activity. Examining the data on a per-thousand inhabitants basis, we found that less densely populated departments experience lower crime rates. As we move forward, we plan to explore the statistical effects by manipulating our real estate data in France, specifically focusing on property prices, to better understand any potential relationships.


### 3.2.1 Average crime rates

#### Interactive map of Crime avg between (2016 and 2021)  

```{r,echo = TRUE, warning = FALSE, message = FALSE}
library(sf)
library(viridis)
library(ggplot2)
library(plotly)
library(dplyr)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate an interactive map for the average of all years with txpourmille
generate_map_avg_txpourmille <- function() {
  # Calculate the average for each department across all years
  avg_data <- main %>%
    group_by(DEPARTEMENT, Libellé) %>%
    summarise(avg_txpourmille = mean(txpourmille, na.rm = TRUE))
  
  # Merge the aggregated data with the map of France
  carte_data_avg <- merge(france, avg_data, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the average of all years with ggplot2
  ggplotly(
    ggplot(data = carte_data_avg) +
      geom_sf(aes(fill = avg_txpourmille, text = paste(Libellé)), lwd = 0.2, color = "white") +
      scale_fill_viridis_c(
        name = "Average Taux pour mille",
        option = "plasma",
        na.value = "grey90",
        direction = -1
      ) +
      theme_minimal() +
      labs(title = "Average Criminality rate in France (2016-2021)", caption = "Source: Your Source Here") +
      theme(
        plot.title = element_text(size = 10, hjust = 0.5) # Adjust the title size and position
      ),
    width = 850,
    height = 450
  )
}

# Generate and print the interactive map for the average of all years
map_avg_txpourmille <- generate_map_avg_txpourmille()

map_avg_txpourmille
```

The interactive map illustrates the average crime rates in France from 2016 to 2020, highlighting departments such as Bouches-du-Rhône, Rhône, Seine-Saint-Denis, Paris, Alpes-Maritimes, and Hérault as high-risk areas. Originally, the data included different types of crimes, but a decision was made to consolidate them into the same category, eliminating the distinction between crime types for the purpose of this analysis.

#### Yearly Average Crime rate per Department 

```{r, echo = TRUE, warning = FALSE, message = FALSE}
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate map for a specific year with txpourmille
generate_map_txpourmille <- function(year) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year using txpourmille
  moyenne_prix_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(moyenne_prix_txpourmille = mean(txpourmille))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, moyenne_prix_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = moyenne_prix_txpourmille), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = "Taux pour mille",
      option = "plasma",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Moyenne du Taux pour mille par Département en", year))
}
# Generate maps for the years 2016 to 2020 using txpourmille
for (year in 2016:2020) {
  map_txpourmille <- generate_map_txpourmille(year)
}
```

::: {.nav-pills}
::: {.panel-tabset}

## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2021.png)

:::
:::

The observed pattern suggests a correlation between criminality and the real estate price map, as similar color patterns emerge. This implies a potential association between criminality, population density, and real estate prices.

### 3.2.2 Crime vs. Population

In this part our aim was to delve into the intricate relationship between department size, categorized into four distinct population groups and the corresponding criminality rates over the years 2016 to 2021. As we navigate through the visual representation in the bar plot, a clear pattern emerges -- a positive correlation unfolds, indicating that larger departments tend to experience higher rates of criminality. What captures our attention is the consistent downward trend in crime rates across all population groups leading up to 2020, followed by a sudden and uniform increase. This anomaly prompts us, as a collective, to pose questions about potential external influences, particularly considering the tumultuous events of the COVID-19 pandemic. This 2020 spike in crime rates prompts us to collectively examine the intricacies and understand the unique dynamics at play. Our collaborative exploration seeks meaningful insights into the interplay between population dynamics and criminality, unraveling the complexity of societal trends.

#### Criminality rate by year and Population Group

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(ggplot2)
library(plotly)
library(dplyr)

# Charger les données
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('orange', 'pink', 'purple', 'blue')

merged_data <- merged_data %>%
  filter(Year >= 2016 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(rate_txpourmille = sum(acts) / sum(POP) * 1000)

ggplot_txpourmille <- ggplot(ggplot_data, aes(x = Year, y = rate_txpourmille, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Criminality rate by year and Population Group",
       x = "Year",
       y = "Rate txpourmille",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
txpourmille_plot <- ggplotly(ggplot_txpourmille, height = 400, width = 700)

txpourmille_plot

```
This plot is an analysis of criminality rates segmented by population groups over several years. The bar chart distinctly displays how crime rates have fluctuated from 2016 to 2021 among different segments of the population. Notably, there is a uniform trend across all groups until a pronounced spike is observed in 2020. This increase may correlate with the socio-economic impacts of the COVID-19 pandemic, which introduced a multitude of stressors on society. The data prompts a need to delve deeper into the correlations between crime rates and external factors such as economic distress, unemployment rates, and societal shifts caused by public health crises. The goal is to draw correlations that can inform policy and prevention strategies, with an eye toward mitigating the factors that led to the 2021 uptick in criminality across all examined population groups.


### 3.2.3 Criminality's impact on Real estate

#### Scatter plot of criminality within the years (2016-2021)

::: panel-tabset

#### 2016

```{r, echo = TRUE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2016)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2017

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2017)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2018

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2018)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2019

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2019)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2020

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2020)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2021

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```
:::

The scatter plot shows the relationship between two variables: average criminality rate per thousands and real estate Average price per square metres. Each dot represents an observation that corresponds to a specific value of criminality and price.

**Positive Correlation Hypothesis:** There is a positive correlation between the price  and criminality rates. As the price increases, so does the criminality rate.

**Economic Activity Hypothesis:** Higher prices might indicate areas with more economic activity, which could correlate with higher crime rates simply due to more opportunities for crime.

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
library(plotly)

# Read the data
merged_data <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

# Create ggplot
ggp <- ggplot(merged_data, aes(x = Prixm2Moyen, y = txpourmille, color = POP, text = paste("DEP:", DEPARTEMENT, "\nYear:", Annee))) +
  scale_color_gradient(low = "blue", high = "green") +
  geom_point(size = 3) +
  labs(title = "Comparison between crime rate and M² price (2016-2021)",
       x = "Average M² Price",
       y = "Crime rates") +
  xlim(0, 6000) +   # Set x-axis range
  ylim(15, 70)   +   # Set y-axis range
  theme_minimal()

# Convert ggplot to plotly
p <- ggplotly(ggp, height = 400, width = 700)

# Customize layout if needed
p

```
This scatter plot show a relationship between the average square meter price of property on the x-axis, crime rates on the y-axis and also Population density with the colour grade. Each point on the scatter plot represents a particular department in a special year.

The group of points with an average square meter price over 1500 euros clearly shows that these are densely populated regions, but also that crime is generally higher. On the other hand, when the price is less than 1500 euros, the population is much lower and so is the crime rate.
We can hypothesize that the price per square meter is positively correlated with population density and crime rates.

#### Criminiality heatmap  

```{r, echo = TRUE, message = FALSE}

# Read data
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

# Filter and aggregate data
df <- data %>%
  filter(Year >= 2016 & Year <= 2021) %>%
  group_by(Year, Group) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts)) %>%
  mutate(criminality = nbcrime / popu * 1000)

# Create ggplot heatmap
gg_heatmap <- ggplot(df, aes(x = Year, y = Group, fill = criminality)) +
  geom_tile() +
  scale_fill_gradientn(colors = brewer.pal(9, "Blues"), name = "Criminality") +
  labs(title = "Criminality Heatmap", x = "Year", y = "Group") +
  theme_minimal()

# Convert ggplot to Plotly
heatmap_plot <- ggplotly(gg_heatmap, height = 400, width = 700)

# Display the plot
heatmap_plot
```
The groups are those selected using the different quantiles above.

This heat map shows that crime is increasing as a function of population density in the groups. We can also clearly see a criminality drop during Covid-19 due to population lock out in France.
The groups are those selected using the different quantiles above.

## 3.3 Population

```{r, echo = TRUE, message = FALSE, warning = FALSE}

PrixPopCrimeYearChomInt_vf <- read_csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomInt_vf.csv")

library(ggplot2)
library(scales)

# Sum the population per year
population_sum <- PrixPopCrimeYearChomInt_vf %>%
  group_by(Annee) %>%
  summarize(TotalPopulation = sum(POP))

# Plotting the graph
ggplot(population_sum, aes(x = Annee, y = TotalPopulation)) +
  geom_line() +
  geom_point() +
  labs(title = "Population per Year",
       x = "Year",
       y = "Total Population (in millions)") +
  scale_y_continuous(labels = scales::comma_format(scale = 1e-6))
```

France's population has steadily increased over the years, signaling ongoing demographic growth with implications for societal dynamics and future planning.

### 3.3.1 Population density

```{r, echo = TRUE, warning = FALSE, message = FALSE}

library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf.csv")

#france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

france <- main

# Function to generate map for a specific year
generate_map <- function(year, variable) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year
  variable_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(variable_value = sum({{variable}}))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, variable_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = variable_value), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = paste("Total ", deparse(substitute(variable)), "\n", sep = ""),
      option = "mako",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Total ", deparse(substitute(variable)), " per Département in", year))


# Generate maps for the years 2014 to 2021 for population (POP)
#for (year in 2014:2021) {
 # map <- generate_map(year, POP)
  #print(map)
  
  # Directory where you want to save the maps
#  output_directory <- "/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/"
  
  # Save the map to the specified directory
 # ggsave(file.path(output_directory, paste("map_POP_", year, ".png", sep = "")), plot = map, width = 10, height = 8)
}

```

#### Yearly average population density 

::: {.nav-pills}
::: {.panel-tabset}

## 2014

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2014.png)

## 2015

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2015.png)
## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2021.png)
:::
:::

Once more, there's a resemblance in the color mapping to real estate prices, prompting consideration of a potential correlation between the two.


### 3.3.2 Real estate in terms of Population

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(ggplot2)
library(plotly)
library(dplyr)

# Charger les données
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('green', 'yellow', 'orange', 'blue')

merged_data <- merged_data %>%
  filter(Year >= 2016 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(priceSQmeter = mean(AvgSQmeter))

ggplot_txpourmille <- ggplot(ggplot_data, aes(x = Year, y = priceSQmeter, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Price/m2 by year and Population Group",
       x = "Year",
       y = "Price/m2",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
leprix <- ggplotly(ggplot_txpourmille, height = 400, width = 700)

leprix

```
This plot analyzes Price per Square Meter rates across population groups from 2016 to 2021. The bar chart reveals fluctuations, with a notable spike in 2020, potentially linked to the socio-economic impacts of the COVID-19 pandemic. Further exploration into correlations with factors like economic distress and unemployment rates is warranted. The aim is to inform strategies addressing the observed 2020 uptick in prices per square meter across all population groups.

## 3.4 Unemployment rate 

#### Unemployment rate in France  

```{r, echo = TRUE , message = FALSE, warning = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(UnemploymentRate = mean(Unemployment))

# Create a plot of crime rate over the years
chomage <- ggplot(new_data, aes(x = Year, y = UnemploymentRate)) +
  geom_line() +
  geom_point() +
  labs(title = "Unemployment Over the Years",
       x = "Year",
       y = "Unemployment in %") +
  theme_minimal()

# Show the plot
print(chomage)
```

The overall unemployment trend shows a decline, but a spike is observed after 2020, indicating a subsequent increase.


#### Unemployment rate in France by group

```{r, echo = TRUE, warning = FALSE, message = FALSE}
ata <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

new_data <- filtered_data %>%
  group_by(Year, Group) %>%
  summarise(UnemploymentRate = mean(Unemployment))


ggplot(new_data, aes(x = Year, y = UnemploymentRate, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Unemployment rate by Group",
       x = "Year",
       y = "Unemployment Rate",
       color = "Group") +
  theme_minimal()
```
Upon closer examination by group, a nuanced picture of unemployment trends emerges. Initially, there is an overall decline in unemployment rates, suggesting positive economic conditions. However, post-2020, a noticeable spike in unemployment is evident, signifying a shift in the trajectory. This increase, observed across various population groups, prompts further exploration into the specific factors contributing to the rise in unemployment. Analyzing these group-specific trends is essential for understanding the diverse impacts of economic fluctuations and tailoring targeted interventions to mitigate the challenges faced by distinct segments of the population.

#### Boxplot Unemployment by group 
```{r, echo = TRUE, message = FALSE}
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('#336600', '#cccc00', '#ffcc66', '#eeccff')

merged_data <- merged_data %>%
  filter(Year >= 2014 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(UnemploymentRate = mean(Unemployment))

ggplot_chomage <- ggplot(ggplot_data, aes(x = Year, y = UnemploymentRate, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Unemployment rate by year and Population Group",
       x = "Year",
       y = "Unemployment rate",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
txpourmille_plot <- ggplotly(ggplot_chomage, height = 400, width = 700) %>%
  layout(yaxis = list(range = c(6, 10.5)))

txpourmille_plot
```

We can see a bar chart of the evolution of the unemployment rate by year and by department group from 2014 to 2021. We can see that unemployment rates vary not only over the years, but also between population groups, possibly classified by departmental population size.

In 2014, unemployment rates for all four groups are relatively high, with a slight decrease for the first group and an increase for the fourth in 2015. From 2016 to 2017, there is a general downward trend in unemployment rates for all groups. However, in 2018, this trend reverses slightly for the fourth group. From 2019 to 2021, all groups appear to be experiencing a decrease in the unemployment rate.

#### Unemployment average in France by department 

```{r, echo= TRUE}

# CARTE

# Load required libraries
# library(sf)                   # For working with spatial data
# library(dplyr)                # For data manipulation
# library(viridis)              # For color scales
# library(ggplot2)              # For plotting

# Read the main dataset
# main <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

# Read the map of France from a GeoJSON file
# france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate a map for a specific year
# generate_map <- function(year) {
#   # Filter the data for the given year
#   main_year <- main %>%
#     filter(Year == year)
  
#   # Aggregate the data by department for the given year
#   moyenne_chomage_year <- main_year %>%
#     group_by(DEPARTEMENT) %>%
#     summarise(moyenne_chomage = mean(Unemployment))
  
#   # Merge the aggregated data with the map of France for the given year
#   carte_chomage_year <- merge(france, moyenne_chomage_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
#   # Create the map for the given year with ggplot2
#   ggplot(data = carte_chomage_year) +
#     geom_sf(aes(fill = moyenne_chomage), lwd = 0.2, color = "white") +
#     scale_fill_viridis_c(
#       name = "Unemployment rate in %",
#       option = "magma",
#       na.value = "grey90",
#       direction = -1
#     ) +
#     theme_minimal() +
#     labs(title = paste("Unemployment rate in", year))
# }

# Generate maps for the years 2014 to 2021
# for (year in 2014:2021) {
#   # Generate map for the current year
#   map <- generate_map(year)
  
#   # Print the map
#   print(map)
  
#   # Directory where you want to save the maps
#   output_directory <- "/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie"
  
#   # Save the map to the specified directory
#   ggsave(file.path(output_directory, paste("map_", year, ".png", sep = "")), plot = map, width = 10, height = 8)
# }
# 

```


::: {.nav-pills}
::: {.panel-tabset}

## 2014

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2014.png)

## 2015

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2015.png)

## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2021.png)

:::
:::



#### Scatter plot of the price in terms of Unemployment 

```{r}
# Read the data
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

merged_data <- data %>%
  group_by(DEPARTEMENT) %>%
  summarise(PriceSQmeter = mean(AvgSQmeter), UnemploymentRate = mean(Unemployment),POP = mean(POP))

# Create ggplot
ggp <- ggplot(merged_data, aes(x = PriceSQmeter, y = UnemploymentRate, color = POP, text = paste("DEP:", DEPARTEMENT))) +
  scale_color_gradient(low = "blue", high = "green") +
  geom_point(size = 3) +
  labs(title = "Comparison between Unemployment rate and M² price (2014-2021)",
       x = "Average M² Price",
       y = "Unemployment rate") +
  theme_minimal()

# Convert ggplot to plotly
p <- ggplotly(ggp, height = 400, width = 700)

# Customize layout if needed
p
```
The scatter plot indicates that departments with lower real estate costs per square meter tend to have smaller populations and higher rates of unemployment. This trend may reflect economic vitality in more densely populated areas, likely due to a variety of employment opportunities and more robust economic activities. In contrast, areas with less population may offer fewer job opportunities, contributing to higher unemployment rates and lower housing costs due to lower demand.

The visualization of data thus leads us to a plausible hypothesis: individuals may be inclined to move towards more populous regions when seeking work, driven by the promise of a more favorable job market.

#### Unemployment heatmap 

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# Read data
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

# Filter and aggregate data
df <- data %>%
  filter(Year >= 2016 & Year <= 2021) %>%
  group_by(Year, Group) %>%
  summarise(UnemploymentRate = mean(Unemployment))

# Create ggplot heatmap
gg_heatmap <- ggplot(df, aes(x = Year, y = Group, fill = UnemploymentRate)) +
  geom_tile() +
  scale_fill_gradientn(colors = brewer.pal(9, "Purples"), name = "UnemploymentRate") +
  labs(title = "UnemploymentRate Heatmap", x = "Year", y = "Group") +
  theme_minimal()

# Convert ggplot to Plotly
heatmap_plot <- ggplotly(gg_heatmap, height = 400, width = 700)

# Display the plot
heatmap_plot
```
The heat map shows the evolution of unemployment rates for four groups of départements ranked by population from 2016 to 2021 The shades of color vary from light to dark indicating unemployment rates of 8 to 10%. The darker the color, the higher the unemployment rate. Groups of departments with larger populations could be those with darker shades suggesting higher unemployment rates. This could indicate economic challenges specific to more populated areas, or labor market dynamics that vary according to population density. The general trend or significant changes over the years could reflect the impact of major economic events or employment policies on different types of departments.

## 3.5 Inflation, Interest Rate & PIB 

```{r, echo = TRUE, message = FALSE, warning = FALSE, out.width='100%'}
library(ggplot2)

data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(InterestRate = mean(interest_rate), Inflation = mean(tx_inflation), GDP = mean(PIB))

# Create a plot of interest rate and inflation over the years with lines and points
interet <- ggplot(new_data, aes(x = Year)) +
  geom_line(aes(y = InterestRate, color = "Interest Rate"), linetype = "solid") +
  geom_point(aes(y = InterestRate, color = "Interest Rate")) +
  
  geom_line(aes(y = Inflation, color = "Inflation"), linetype = "dashed") +
  geom_point(aes(y = Inflation, color = "Inflation")) +
  
  geom_line(aes(y = GDP, color = "GDP"), linetype = "solid") +
  geom_point(aes(y = GDP, color = "GDP")) +
  
  geom_bar(aes(x = Year, y = Inflation), stat = "identity", fill = "orange", alpha = 0.5) +
  geom_bar(aes(x = Year, y = InterestRate), stat = "identity", fill = "blue", alpha = 0.5) +
  geom_bar(aes(x = Year, y = GDP), stat = "identity", fill = "black", alpha = 0.5) +
  
  labs(title = "Interest Rate, Inflation & GDP Over the Years",
       x = "Year",
       y = "Value") +
  theme_minimal() +
  scale_color_manual(values = c("Interest Rate" = "blue", "Inflation" = "orange", "GDP" = "black"), 
                     name = "Legend Title")

# Show the plot
print(interet)
```
The graph  show how these macroeconomic indicators have moved over the years, which can be important for analyzing economic health, setting monetary policy, and understanding market trends. We can observe here a falling trend of every macroeconomic factors during covid-19 pandemic and a raise of variables.

## 3.7 Multipanel variables  

#### Panel 

```{r, echo = TRUE, message = FALSE, warning = FALSE, out.width='80%'}
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(pop = sum(POP), sales = sum(Nb_sales), price =  mean(AvgSQmeter),surface = mean(Surface), crime = mean(criminality), chomage = mean(Unemployment),
           interest =  mean(interest_rate), inflation = mean(tx_inflation), PIB = mean(PIB) )

# Assuming your dataset is named 'new_data'

# Melt the data to long format
new_data_long <- new_data %>%
  gather(variable, value, -Year)

# Create a facet plot for each variable
facet_plot <- ggplot(new_data_long, aes(x = Year, y = value, color = variable)) +
  geom_line() +
  geom_point() +
  facet_wrap(~variable, scales = "free_y") +
  labs(title = "Multiple Variables by Year",
       x = "Year",
       y = "Value") +
  theme_minimal()

# Show the plot
print(facet_plot)
```
Here we have trends in selected variables over the period 2014 to 2021. We can see that GDP, population, inflation, property prices, sales and area sold are all on the rise. On the other hand, interest rates, crime and unemployment are falling. We can hypothesize that there is a potential negative correlation between these variables, which we will study in greater depth during the analysis.

#### Correlation map with all the variables 

```{r, echo = TRUE, warning = FALSE, message = FALSE, out.width='100%'}
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT) %>%
  summarise(pop = mean(POP), sales = mean(Nb_sales), price =  mean(AvgSQmeter),surface = mean(Surface), criminality = mean(criminality), chomage = mean(Unemployment),
            interest =  mean(interest_rate), inflation = mean(tx_inflation),  PIB = mean(PIB))


cor_vars <- select_if(new_data, is.numeric)

# Calculate the correlation matrix
cor_matrix <- cor(cor_vars)

# Plot the correlation matrix using corrplot
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8, tl.col = "black")
```
By creating a correlation graph of the selected variables, we can get a first idea of the potential correlations we may have. For exemple,Red collor show a strong negative correlation, white is no correlation and dark blue for a strong positive correlation. This graph should be read with caution, as we don't know whether the relationships are significant.
We will study all these correlations in greater depth in the analysis with more advanced statistical methods.