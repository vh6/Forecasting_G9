---
editor: 
  markdown: 
    wrap: sentence
---

# Exploratory Data Analysis (EDA)

```{r, echo = FALSE, message = FALSE}
(here::here("scripts/setup.R"))
```

#### Loading Packages

This block of code loads several essential packages that are used throughout the data analysis.
Each package serves a specific function, from data manipulation and visualization to time series forecasting.

```{r}
# Load packages
library(tidyverse)
library(lubridate)
library(fpp3)
library(stats)
library(dplyr)
library(ggplot2)
library(fable)
library(tsibble)
library(fabletools)
library(patchwork)

```

This block of code loads several essential packages that are used throughout the data analysis.
Each package serves a specific function, from data manipulation and visualization to time series forecasting.

#### Loading and Preparing Data

```{r, echo = TRUE, message = FALSE}
# Load data
df <- read.csv("Dataset_tourism.csv", stringsAsFactors = FALSE)

# Translate Monat column to English
german_months <- c("Januar", "Februar", "M\xe4rz", "April", "Mai", "Juni", 
                   "Juli", "August", "September", "Oktober", "November", "Dezember")
english_months <- month.name

# Replace German month names with English month names
df$Monat <- factor(df$Monat, levels = german_months, labels = english_months)
```

Here, the code loads a dataset from a CSV file.
It also handles the conversion of German month names into English, ensuring the data is accessible and ready for analysis.
This step is crucial for preparing the dataset for time-series analysis, as date formatting must be consistent.

#### Counting Missing Values

```{r,echo = TRUE}

# Count NAs
sum(is.na(df$Jahr)) # 0 NAs
sum(is.na(df$Monat)) # 0 NAs
sum(is.na(df$date)) # 0 NAs
sum(is.na(df$value)) # 51395 NAs
sum(is.na(df$Kanton)) # 0 NAs
sum(is.na(df$Herkunftsland)) # 0 NAs

```

This segment of code counts and reports the number of missing (NA) values in various columns of the dataset.
This is an important step to identify and address any data quality issues before proceeding with further analysis.

#### Forecasting Total Visitors to Vaud

This section outlines the methodology for predicting the number of visitors to Vaud, focusing on handling the dataset to ensure accurate and unbiased forecasting.

#### Data Preparation

```{r, echo = TRUE, warning = FALSE}

# Subset dataframe to remove nationalities and cantons, and keep totals.
df <- df[df$Herkunftsland == "Herkunftsland - Total" & df$Kanton == "Vaud", ]

```

The initial step involves subsetting the data to focus specifically on the overall visitor statistics for the canton of Vaud, removing entries related to specific nationalities and other cantons.
This ensures that the analysis is targeted and relevant to the specific geographic area of interest.

#### Time Series Data Transformation

```{r, echo = TRUE}
# Transform df to tsibble
df <- tsibble(df, index = date)

```

The data is then transformed into a tsibble, a time series data frame that facilitates handling and modeling time series in a tidyverse-compatible way.
This format is particularly useful for the subsequent steps in time series analysis and forecasting.

#### Visualization of Visitor Trends

```{r, echo = TRUE, message = FALSE, out.width='100%'}
# Plot visitors
df |> autoplot(value) +
  ggtitle("Monthly visitors to Vaud") +
  ylab("Visitors") +
  xlab("Months")

# We see an upwards trend with seasonality, and a little bit of noise. We also see a strong dip in the amount of visitors during COVID, which will bias our model.
# We will add a dummy variable for all observations during covid, so we may remove them when creating a model in order to not bias our model.
# We consider COVID to be a black swan, and a unique event, and we will assume that it will not happen again during the period that we are predicting (Oct 23 - Dec 24).
# Lockdown started in March 2020, and all measures except masks were lifted indefinitely in February 2022.


```

This code creates a graph that clearly shows the monthly visitor trends, with appropriate titles and labels for the axes.
We also observed an upward trend with seasonality and noted a significant dip during the COVID-19 period.
We plan to add a dummy variable for this period to avoid biasing the model.
This approach allows us to isolate the effect of COVID-19 on tourist data and prepare a more robust model that does not consider this event as recurring.

Finally, we accounted for the lockdown period and related restrictions, deciding to treat them as a non-recurring exceptional event in our prediction period.
This is crucial to ensure that our model predicts future trends without being influenced by past anomalies.

Our approach demonstrates a deep understanding of the challenges associated with time series data analysis and how to effectively handle them to obtain useful and applicable predictions.

```{r}
# Add dummy variable covid, set to 1 between March 2020 and Feb 2022, 0 everywhere else.
df$covid <- ifelse(df$date >= ymd("2020-03-01") & df$date <= ymd("2022-02-01"), 1, 0)

```

In this code, a dummy variable named covid is introduced to the dataset to specifically mark the period affected by the COVID-19 pandemic.
Using the ifelse function, each entry in the date column of the dataframe is checked.
If a date falls within the range from March 1st, 2020, to February 1st, 2022, the function assigns a 1 to the covid column for that row.
This value indicates the timeframe of major disruptions due to the pandemic, such as lockdowns and significant travel restrictions.
For dates outside this specified range, a 0 is assigned, indicating periods considered to be unaffected by COVID-19.
This differentiation is crucial for any subsequent analysis where the impact of the pandemic might skew results, allowing for adjustments or filtering in modeling efforts.
The use of the ymd function from the lubridate package ensures that the dates are accurately handled, converting string representations into proper date objects and facilitating precise date comparisons in the analysis.
This method effectively segments the data, enabling a detailed study of how the pandemic has influenced the observed trends.

### 3.1.2 Average Price Observations

```{r, echo = TRUE}

PrixPopCrimeYearChomInt_vf <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

library(ggplot2)
library(dplyr)

# Calculate the average Prixm2Moyen per year
average_prices <- PrixPopCrimeYearChomInt_vf %>%
  group_by(Annee) %>%
  summarise(Avg_Prixm2Moyen = mean(Prixm2Moyen))

# Plot the average Prixm2Moyen per year with filled area under the curve
ggplot(average_prices, aes(x = Annee, y = Avg_Prixm2Moyen)) +
  geom_line() +
  labs(title = "Average Prixm2Moyen per Year",
       x = "Year",
       y = "Average Prixm2Moyen")
```

This plot shows the average price per square meter of real estate from 2014 to 2021.
The line graph illustrates a significant increase in prices, especially noticeable after 2018.
This steep upward trend in the average price indicates a robust growth in the real estate market, potentially reflecting factors such as increased demand, economic growth, or a reduction in supply.

#### Average Price per group

```{r, echo = TRUE, message = FALSE}
#breaks = c(0, 250000, 500000, 800000, 3000000),
#labels = c("Group 1", "Group 2", "Group 3", "Group 4"))

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

new_data <- data %>%
  group_by(Year, Group) %>%
  summarise(avg_Prixm2Moyen = mean(AvgSQmeter))

# Plotting the average Prixm2Moyen in terms of year by group
ggplot(new_data, aes(x = Year, y = avg_Prixm2Moyen, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Avg Price/m² by Group",
       x = "Year",
       y = "Price/m²",
       color = "Group") +
  theme_minimal()
```

On this graph we can see the price trends for the different groups selected earlier.
Group 4 stands out for its high prices, but we can also see that all the groups have been growing since 2014.
We can therefore say that the real estate market in France has been growing overall since 2014, except for a slight decline in rural areas in 2016.

#### Histogram price frequency

```{r, echo = TRUE}
#TOTAL average price m2
mainXpop2 <- read_csv("~/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")
hist(mainXpop2$Prixm2Moyen, main = "Average Price/m2", col = "pink", xlab = "Average Price", xlim = c(0, 8000))
```

This histogram illustrating the distribution of the total average price per square meter (**`AveragePrice/m2`**) in the dataset.
The visualization offers insights into the variation and frequency of average prices per square meter within the specified range, contributing to the broader exploration of real estate market dynamics in France.

#### Price frequency Curve

```{r, echo = TRUE, fig.width=15, fig.height=9}

mainXpop2 <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/mainXpop2.csv")
                      
#TOTAL average price m2/ year 
ggplot(mainXpop2, aes(x = Prixm2Moyen)) +
  geom_histogram(binwidth = 100, position = "identity", alpha = 0.7, fill = "blue") +
  labs(title = "Histogram of AveragePricem2",
       x = "AvPricem2",
       y = "Frequency") +
  facet_wrap(~Annee, scales = "free",  ncol = 4) +
  theme_minimal()+
  scale_x_continuous(labels = scales::comma_format(scale = 1e-3, suffix = "k")) +
  coord_cartesian(xlim = c(0, 8000))
```

The depicted left-skewed trend and consistent pattern over the years remain evident in the distribution of the average price per square meter (**`Prixm2Moyen`**).
The increasing frequency of prices exceeding the average in both total average price and price per square meter suggests a cohesive upward trajectory in real estate values throughout the specified time period, emphasizing a linked relationship between the two metrics.

#### Box and Whisker Plot: Price Distribution by Department

```{r, echo = TRUE}

# Boxplot for Price Distribution by Department with adjusted aspect ratio
#boxplot(Prixm2Moyen ~ DEPARTEMENT, data = main, col = "skyblue", 
# main = "Price/m2 Distribution by Department")
```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Groupe-AI/plot1.png){width="800"} In examining the data by department, noticeable outliers are evident, suggesting instances of exaggeration, likely influenced by unique values in certain departments or even specific communes.
At this juncture, opting for the median over the mean proves more insightful due to its robustness in handling extreme values.

#### Scatter: Price in terms of Surface

```{r, echo = TRUE, message = FALSE}

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

#new_data <- data %>%
#  group_by(Annee, DEPARTEMENT) %>%
#  summarise(avgSurface = mean(SurfaceMoy), Prixm2Moyen = mean(Prixm2Moyen))

#ggplot(new_data, aes(x = avgSurface, y = Prixm2Moyen, color = as.factor(Annee))) +
# geom_point() +
# geom_smooth(method = "lm", se = FALSE, size = 0.8) +  # Add regression line
# facet_wrap(~Annee, scales = "free", ncol = 2) +  # 2 columns in each row
# labs(title = "Scatter Plot: Prixm2Moyen vs avgSurface",
#     x = "avgSurface",
#      y = "Prixm2Moyen",
#     color = "Year") +
# theme_minimal()

```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/scatter_surface.png) This scatterplot illustrates the relationship between the average surface area (**`SurfaceMoy`**) and the average price per square meter (**`Prixm2Moyen`**).
The negative slope of the added regression line (abline) indicates an inverse correlation: as the surface area increases, the average price per square meter tends to decrease.
This suggests a potential trend where larger properties have a lower price per square meter compared to smaller ones, providing valuable insights into the pricing dynamics within the dataset.
The inclusion of the regression line enhances the visualization by highlighting this negative correlation trend.

#### Scatter: Price in terms of Surface by Group

```{r, echo = TRUE}
# data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
# 
# new_data <- data %>%
#   group_by(Annee, DEPARTEMENT, Group) %>%
#   summarise(avgSurface = mean(SurfaceMoy), Prixm2Moyen = mean(Prixm2Moyen))
# 
# library(ggplot2)
# 
# # Assuming your data frame is named new_data
# # Create the scatter plot with regression line for each year and each group
# plot <- ggplot(new_data, aes(x = avgSurface, y = Prixm2Moyen, color = Group)) +
#   geom_point() +
#   geom_smooth(method = "lm", se = FALSE) +  # Add regression line without confidence interval
#   facet_wrap(~Annee, ncol = 2) +  # Facet by year
#   labs(title = "Scatter Plot and Regression Lines by Group",
#        x = "Average Surface",
#        y = "Prixm2Moyen") +
#   theme_minimal()+
#   xlim(85, 115) +  # Set x-axis limits
#   ylim(800, 3500)  # Set y-axis limits
# 
# # Show the plot
# print(plot)

```

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/scatter_by_group.png) After segregating the data by population groups (low, average, high, very high), a distinct pattern emerges.
It becomes evident that in the most densely populated areas in France, there is a tendency for larger properties to exhibit lower prices per square meter.
On the contrary, in rural environments, this trend is less pronounced, and in some instances, it even reverses, indicating a potential inversion of the relationship between property size and price in less densely populated regions.

#### Yearly Real estate average price in France

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Main /main.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate map for a specific year
generate_map <- function(year) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year
  moyenne_prix_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(moyenne_prix_m2 = mean(Prixm2Moyen))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, moyenne_prix_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = moyenne_prix_m2), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = "Moyenne\nPrix/m2",
      option = "magma",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Moyenne du Prix au mètre carré par Département en", year))
}

# Generate maps for the years 2014 to 2021
for (year in 2014:2021) {
  map <- generate_map(year)
}
```

In this R code, the objective is to conduct a geospatial analysis to visualize and understand the spatial distribution of average real estate prices per square meter across different departments in France from 2014 to 2021.
The code involves reading a primary dataset containing relevant real estate information, including the average prices.
It then utilizes geographical data in a GeoJSON file outlining the boundaries of French departments.
For each year in the range 2014 to 2021, the code filters and aggregates the data, creating thematic maps using **`ggplot2`** and **`sf`**.
These maps use color gradients to represent the variation in average prices, with the **`viridis`** package providing a visually appealing color scale.
Finally, the maps are saved as PNG images, enabling a comprehensive visual exploration of how real estate prices have evolved across different regions of France over the specified time period.

::: nav-pills
::: panel-tabset
## 2014

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2014.png)

## 2015

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2015.png)

## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/Carte_2014-2021/map_2021.png)
:::
:::

The script then iterates through the years 2014 to 2021, generating maps for each year and saving them as PNG files.
The maps visually represent the average real estate prices per square meter in French departments, with color-coded regions indicating varying price levels.
The use of libraries like sf, dplyr, and ggplot2 streamlines spatial data handling and visualization, making the code concise and effective for creating a series of informative maps over multiple years.
Additionally, the use of loops and functions enhances code reusability and readability.

Observing the real estate market dynamics during the COVID period, a noteworthy pattern emerges, revealing an upward trend in prices along the coastline and in rural areas.
This shift implies a growing preference among individuals to move away from urban centers, possibly influenced by changing lifestyle preferences and a heightened appreciation for more spacious and serene environments.
The increased demand in these locations could be a reflection of a broader societal trend driven by the pandemic, where individuals seek homes in areas offering tranquility and proximity to nature, contributing to the observed price surge in coastal and rural real estate markets.

## 3.2 Criminality in France

#### Crime rate over the years

```{r, echo = TRUE, message = FALSE, warning = FALSE }

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts))

# Create a new column named 'criminality' as crimes per 1000 population
new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

# Create a plot of crime rate over the years
crime_plot <- ggplot(new_data, aes(x = Year, y = criminality)) +
  geom_line() +
  geom_point() +
  labs(title = "Crime Rate Over the Years",
       x = "Year",
       y = "Crime Rate per ‰") +
  theme_minimal()

# Show the plot
print(crime_plot)
```

In our real estate project in France, we are examining various socio-demographic factors, including the analysis of crime rates in France from 2016 to 2021.
Initially, we hypothesized that higher crime rates might be associated with lower-cost housing.
However, upon closer inspection, we observed a correlation indicating that in major cities like Paris, the crime rate tends to increase with population density.

#### Crime rate over the years by group

```{r, echo = TRUE, message = FALSE, warning = FALSE }

data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

new_data <- filtered_data %>%
  group_by(Year, Group) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)


ggplot(new_data, aes(x = Year, y = criminality, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Avg Crime rate by Group",
       x = "Year",
       y = "Crime rate",
       color = "Group") +
  theme_minimal()
```

This observation aligns with the logical expectation that more populated areas are likely to have higher chances of criminal activity.
Examining the data on a per-thousand inhabitants basis, we found that less densely populated departments experience lower crime rates.
As we move forward, we plan to explore the statistical effects by manipulating our real estate data in France, specifically focusing on property prices, to better understand any potential relationships.

### 3.2.1 Average crime rates

#### Interactive map of Crime avg between (2016 and 2021)

```{r,echo = TRUE, warning = FALSE, message = FALSE}
library(sf)
library(viridis)
library(ggplot2)
library(plotly)
library(dplyr)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate an interactive map for the average of all years with txpourmille
generate_map_avg_txpourmille <- function() {
  # Calculate the average for each department across all years
  avg_data <- main %>%
    group_by(DEPARTEMENT, Libellé) %>%
    summarise(avg_txpourmille = mean(txpourmille, na.rm = TRUE))
  
  # Merge the aggregated data with the map of France
  carte_data_avg <- merge(france, avg_data, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the average of all years with ggplot2
  ggplotly(
    ggplot(data = carte_data_avg) +
      geom_sf(aes(fill = avg_txpourmille, text = paste(Libellé)), lwd = 0.2, color = "white") +
      scale_fill_viridis_c(
        name = "Average Taux pour mille",
        option = "plasma",
        na.value = "grey90",
        direction = -1
      ) +
      theme_minimal() +
      labs(title = "Average Criminality rate in France (2016-2021)", caption = "Source: Your Source Here") +
      theme(
        plot.title = element_text(size = 10, hjust = 0.5) # Adjust the title size and position
      ),
    width = 850,
    height = 450
  )
}

# Generate and print the interactive map for the average of all years
map_avg_txpourmille <- generate_map_avg_txpourmille()

map_avg_txpourmille
```

The interactive map illustrates the average crime rates in France from 2016 to 2020, highlighting departments such as Bouches-du-Rhône, Rhône, Seine-Saint-Denis, Paris, Alpes-Maritimes, and Hérault as high-risk areas.
Originally, the data included different types of crimes, but a decision was made to consolidate them into the same category, eliminating the distinction between crime types for the purpose of this analysis.

#### Yearly Average Crime rate per Department

```{r, echo = TRUE, warning = FALSE, message = FALSE}
library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

# Lire le fichier JSON https://www.data.gouv.fr/fr/datasets/carte-des-departements-2-1/
france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate map for a specific year with txpourmille
generate_map_txpourmille <- function(year) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year using txpourmille
  moyenne_prix_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(moyenne_prix_txpourmille = mean(txpourmille))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, moyenne_prix_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = moyenne_prix_txpourmille), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = "Taux pour mille",
      option = "plasma",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Moyenne du Taux pour mille par Département en", year))
}
# Generate maps for the years 2016 to 2020 using txpourmille
for (year in 2016:2020) {
  map_txpourmille <- generate_map_txpourmille(year)
}
```

::: nav-pills
::: panel-tabset
## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_txpourmille_2021.png)
:::
:::

The observed pattern suggests a correlation between criminality and the real estate price map, as similar color patterns emerge.
This implies a potential association between criminality, population density, and real estate prices.

### 3.2.2 Crime vs. Population

In this part our aim was to delve into the intricate relationship between department size, categorized into four distinct population groups and the corresponding criminality rates over the years 2016 to 2021.
As we navigate through the visual representation in the bar plot, a clear pattern emerges -- a positive correlation unfolds, indicating that larger departments tend to experience higher rates of criminality.
What captures our attention is the consistent downward trend in crime rates across all population groups leading up to 2020, followed by a sudden and uniform increase.
This anomaly prompts us, as a collective, to pose questions about potential external influences, particularly considering the tumultuous events of the COVID-19 pandemic.
This 2020 spike in crime rates prompts us to collectively examine the intricacies and understand the unique dynamics at play.
Our collaborative exploration seeks meaningful insights into the interplay between population dynamics and criminality, unraveling the complexity of societal trends.

#### Criminality rate by year and Population Group

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(ggplot2)
library(plotly)
library(dplyr)

# Charger les données
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('orange', 'pink', 'purple', 'blue')

merged_data <- merged_data %>%
  filter(Year >= 2016 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(rate_txpourmille = sum(acts) / sum(POP) * 1000)

ggplot_txpourmille <- ggplot(ggplot_data, aes(x = Year, y = rate_txpourmille, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Criminality rate by year and Population Group",
       x = "Year",
       y = "Rate txpourmille",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
txpourmille_plot <- ggplotly(ggplot_txpourmille, height = 400, width = 700)

txpourmille_plot

```

This plot is an analysis of criminality rates segmented by population groups over several years.
The bar chart distinctly displays how crime rates have fluctuated from 2016 to 2021 among different segments of the population.
Notably, there is a uniform trend across all groups until a pronounced spike is observed in 2020.
This increase may correlate with the socio-economic impacts of the COVID-19 pandemic, which introduced a multitude of stressors on society.
The data prompts a need to delve deeper into the correlations between crime rates and external factors such as economic distress, unemployment rates, and societal shifts caused by public health crises.
The goal is to draw correlations that can inform policy and prevention strategies, with an eye toward mitigating the factors that led to the 2021 uptick in criminality across all examined population groups.

### 3.2.3 Criminality's impact on Real estate

#### Scatter plot of criminality within the years (2016-2021)

::: panel-tabset
#### 2016

```{r, echo = TRUE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2016)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2017

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2017)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2018

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2018)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2019

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2019)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2020

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2020)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```

#### 2021

```{r, echo = FALSE, warning = FALSE, message = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  #filter(Annee >= 2016 & Annee <= 2021)
  filter(Year == 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT)%>%
  summarise(popu = sum(POP), nbcrime = sum(acts), price = mean(AvgSQmeter))

new_data <- new_data %>%
  mutate(criminality = nbcrime / popu * 1000)

scatter_plot <- ggplot(new_data, aes(x = price, y = criminality)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "blue") +  # Add linear regression line without confidence interval
  labs(title = "Scatter Plot of Criminality vs Price with Regression Line",
       x = "Price",
       y = "Criminality") +
  theme_minimal()+
  xlim(800, 4000) +
  ylim(15, 80)

# Show the plot
print(scatter_plot)
```
:::

The scatter plot shows the relationship between two variables: average criminality rate per thousands and real estate Average price per square metres.
Each dot represents an observation that corresponds to a specific value of criminality and price.

**Positive Correlation Hypothesis:** There is a positive correlation between the price and criminality rates.
As the price increases, so does the criminality rate.

**Economic Activity Hypothesis:** Higher prices might indicate areas with more economic activity, which could correlate with higher crime rates simply due to more opportunities for crime.

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)
library(plotly)

# Read the data
merged_data <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYear_vf.csv")

# Create ggplot
ggp <- ggplot(merged_data, aes(x = Prixm2Moyen, y = txpourmille, color = POP, text = paste("DEP:", DEPARTEMENT, "\nYear:", Annee))) +
  scale_color_gradient(low = "blue", high = "green") +
  geom_point(size = 3) +
  labs(title = "Comparison between crime rate and M² price (2016-2021)",
       x = "Average M² Price",
       y = "Crime rates") +
  xlim(0, 6000) +   # Set x-axis range
  ylim(15, 70)   +   # Set y-axis range
  theme_minimal()

# Convert ggplot to plotly
p <- ggplotly(ggp, height = 400, width = 700)

# Customize layout if needed
p

```

This scatter plot show a relationship between the average square meter price of property on the x-axis, crime rates on the y-axis and also Population density with the colour grade.
Each point on the scatter plot represents a particular department in a special year.

The group of points with an average square meter price over 1500 euros clearly shows that these are densely populated regions, but also that crime is generally higher.
On the other hand, when the price is less than 1500 euros, the population is much lower and so is the crime rate.
We can hypothesize that the price per square meter is positively correlated with population density and crime rates.

#### Criminiality heatmap

```{r, echo = TRUE, message = FALSE}

# Read data
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

# Filter and aggregate data
df <- data %>%
  filter(Year >= 2016 & Year <= 2021) %>%
  group_by(Year, Group) %>%
  summarise(popu = sum(POP), nbcrime = sum(acts)) %>%
  mutate(criminality = nbcrime / popu * 1000)

# Create ggplot heatmap
gg_heatmap <- ggplot(df, aes(x = Year, y = Group, fill = criminality)) +
  geom_tile() +
  scale_fill_gradientn(colors = brewer.pal(9, "Blues"), name = "Criminality") +
  labs(title = "Criminality Heatmap", x = "Year", y = "Group") +
  theme_minimal()

# Convert ggplot to Plotly
heatmap_plot <- ggplotly(gg_heatmap, height = 400, width = 700)

# Display the plot
heatmap_plot
```

The groups are those selected using the different quantiles above.

This heat map shows that crime is increasing as a function of population density in the groups.
We can also clearly see a criminality drop during Covid-19 due to population lock out in France.
The groups are those selected using the different quantiles above.

## 3.3 Population

```{r, echo = TRUE, message = FALSE, warning = FALSE}

PrixPopCrimeYearChomInt_vf <- read_csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomInt_vf.csv")

library(ggplot2)
library(scales)

# Sum the population per year
population_sum <- PrixPopCrimeYearChomInt_vf %>%
  group_by(Annee) %>%
  summarize(TotalPopulation = sum(POP))

# Plotting the graph
ggplot(population_sum, aes(x = Annee, y = TotalPopulation)) +
  geom_line() +
  geom_point() +
  labs(title = "Population per Year",
       x = "Year",
       y = "Total Population (in millions)") +
  scale_y_continuous(labels = scales::comma_format(scale = 1e-6))
```

France's population has steadily increased over the years, signaling ongoing demographic growth with implications for societal dynamics and future planning.

### 3.3.1 Population density

```{r, echo = TRUE, warning = FALSE, message = FALSE}

library(sf)
library(dplyr)
library(viridis)
library(ggplot2)

main <- read.csv("/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf.csv")

#france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

france <- main

# Function to generate map for a specific year
generate_map <- function(year, variable) {
  # Filter the data for the given year
  main_year <- main %>%
    filter(Annee == year)
  
  # Aggregate the data by department for the given year
  variable_year <- main_year %>%
    group_by(DEPARTEMENT) %>%
    summarise(variable_value = sum({{variable}}))
  
  # Merge the aggregated data with the map of France for the given year
  carte_data_year <- merge(france, variable_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
  # Create the map for the given year with ggplot2
  ggplot(data = carte_data_year) +
    geom_sf(aes(fill = variable_value), lwd = 0.2, color = "white") +
    scale_fill_viridis_c(
      name = paste("Total ", deparse(substitute(variable)), "\n", sep = ""),
      option = "mako",
      na.value = "grey90",
      direction = -1
    ) +
    theme_minimal() +
    labs(title = paste("Total ", deparse(substitute(variable)), " per Département in", year))


# Generate maps for the years 2014 to 2021 for population (POP)
#for (year in 2014:2021) {
 # map <- generate_map(year, POP)
  #print(map)
  
  # Directory where you want to save the maps
#  output_directory <- "/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/"
  
  # Save the map to the specified directory
 # ggsave(file.path(output_directory, paste("map_POP_", year, ".png", sep = "")), plot = map, width = 10, height = 8)
}

```

#### Yearly average population density

::: nav-pills
::: panel-tabset
## 2014

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2014.png)

## 2015

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2015.png) \## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/report/map_POP_2021.png)
:::
:::

Once more, there's a resemblance in the color mapping to real estate prices, prompting consideration of a potential correlation between the two.

### 3.3.2 Real estate in terms of Population

```{r, echo = TRUE, message = FALSE, warning = FALSE}
library(ggplot2)
library(plotly)
library(dplyr)

# Charger les données
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('green', 'yellow', 'orange', 'blue')

merged_data <- merged_data %>%
  filter(Year >= 2016 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(priceSQmeter = mean(AvgSQmeter))

ggplot_txpourmille <- ggplot(ggplot_data, aes(x = Year, y = priceSQmeter, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Price/m2 by year and Population Group",
       x = "Year",
       y = "Price/m2",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
leprix <- ggplotly(ggplot_txpourmille, height = 400, width = 700)

leprix

```

This plot analyzes Price per Square Meter rates across population groups from 2016 to 2021.
The bar chart reveals fluctuations, with a notable spike in 2020, potentially linked to the socio-economic impacts of the COVID-19 pandemic.
Further exploration into correlations with factors like economic distress and unemployment rates is warranted.
The aim is to inform strategies addressing the observed 2020 uptick in prices per square meter across all population groups.

## 3.4 Unemployment rate

#### Unemployment rate in France

```{r, echo = TRUE , message = FALSE, warning = FALSE}
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(UnemploymentRate = mean(Unemployment))

# Create a plot of crime rate over the years
chomage <- ggplot(new_data, aes(x = Year, y = UnemploymentRate)) +
  geom_line() +
  geom_point() +
  labs(title = "Unemployment Over the Years",
       x = "Year",
       y = "Unemployment in %") +
  theme_minimal()

# Show the plot
print(chomage)
```

The overall unemployment trend shows a decline, but a spike is observed after 2020, indicating a subsequent increase.

#### Unemployment rate in France by group

```{r, echo = TRUE, warning = FALSE, message = FALSE}
ata <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

new_data <- filtered_data %>%
  group_by(Year, Group) %>%
  summarise(UnemploymentRate = mean(Unemployment))


ggplot(new_data, aes(x = Year, y = UnemploymentRate, color = Group)) +
  geom_line() +
  geom_point() +
  labs(title = "Yearly Unemployment rate by Group",
       x = "Year",
       y = "Unemployment Rate",
       color = "Group") +
  theme_minimal()
```

Upon closer examination by group, a nuanced picture of unemployment trends emerges.
Initially, there is an overall decline in unemployment rates, suggesting positive economic conditions.
However, post-2020, a noticeable spike in unemployment is evident, signifying a shift in the trajectory.
This increase, observed across various population groups, prompts further exploration into the specific factors contributing to the rise in unemployment.
Analyzing these group-specific trends is essential for understanding the diverse impacts of economic fluctuations and tailoring targeted interventions to mitigate the challenges faced by distinct segments of the population.

#### Boxplot Unemployment by group

```{r, echo = TRUE, message = FALSE}
merged_data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

my_colors <- c('#336600', '#cccc00', '#ffcc66', '#eeccff')

merged_data <- merged_data %>%
  filter(Year >= 2014 & Year <= 2021)

# Bar plot pour txpourmille par année et groupe de population avec ggplot2
ggplot_data <- merged_data %>%
  group_by(Year, Group) %>%
  summarize(UnemploymentRate = mean(Unemployment))

ggplot_chomage <- ggplot(ggplot_data, aes(x = Year, y = UnemploymentRate, fill = Group)) +
  scale_fill_manual(values = my_colors) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(title = "Unemployment rate by year and Population Group",
       x = "Year",
       y = "Unemployment rate",
       fill = "Population Group") +
  theme_minimal()

# Convertir le graphique ggplot2 en plotly
txpourmille_plot <- ggplotly(ggplot_chomage, height = 400, width = 700) %>%
  layout(yaxis = list(range = c(6, 10.5)))

txpourmille_plot
```

We can see a bar chart of the evolution of the unemployment rate by year and by department group from 2014 to 2021.
We can see that unemployment rates vary not only over the years, but also between population groups, possibly classified by departmental population size.

In 2014, unemployment rates for all four groups are relatively high, with a slight decrease for the first group and an increase for the fourth in 2015.
From 2016 to 2017, there is a general downward trend in unemployment rates for all groups.
However, in 2018, this trend reverses slightly for the fourth group.
From 2019 to 2021, all groups appear to be experiencing a decrease in the unemployment rate.

#### Unemployment average in France by department

```{r, echo= TRUE}

# CARTE

# Load required libraries
# library(sf)                   # For working with spatial data
# library(dplyr)                # For data manipulation
# library(viridis)              # For color scales
# library(ggplot2)              # For plotting

# Read the main dataset
# main <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

# Read the map of France from a GeoJSON file
# france <- st_read("/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/contour-des-departements.geojson")

# Function to generate a map for a specific year
# generate_map <- function(year) {
#   # Filter the data for the given year
#   main_year <- main %>%
#     filter(Year == year)
  
#   # Aggregate the data by department for the given year
#   moyenne_chomage_year <- main_year %>%
#     group_by(DEPARTEMENT) %>%
#     summarise(moyenne_chomage = mean(Unemployment))
  
#   # Merge the aggregated data with the map of France for the given year
#   carte_chomage_year <- merge(france, moyenne_chomage_year, by.x = "code", by.y = "DEPARTEMENT", all.x = TRUE)
  
#   # Create the map for the given year with ggplot2
#   ggplot(data = carte_chomage_year) +
#     geom_sf(aes(fill = moyenne_chomage), lwd = 0.2, color = "white") +
#     scale_fill_viridis_c(
#       name = "Unemployment rate in %",
#       option = "magma",
#       na.value = "grey90",
#       direction = -1
#     ) +
#     theme_minimal() +
#     labs(title = paste("Unemployment rate in", year))
# }

# Generate maps for the years 2014 to 2021
# for (year in 2014:2021) {
#   # Generate map for the current year
#   map <- generate_map(year)
  
#   # Print the map
#   print(map)
  
#   # Directory where you want to save the maps
#   output_directory <- "/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie"
  
#   # Save the map to the specified directory
#   ggsave(file.path(output_directory, paste("map_", year, ".png", sep = "")), plot = map, width = 10, height = 8)
# }
# 

```

::: nav-pills
::: panel-tabset
## 2014

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2014.png)

## 2015

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2015.png)

## 2016

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2016.png)

## 2017

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2017.png)

## 2018

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2018.png)

## 2019

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2019.png)

## 2020

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2020.png)

## 2021

![](/Users/victorregly/MyDoc/University/Master/Management/DATA/Dataset/Cartographie/map_2021.png)
:::
:::

#### Scatter plot of the price in terms of Unemployment

```{r}
# Read the data
data <- read_delim("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf3.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)

merged_data <- data %>%
  group_by(DEPARTEMENT) %>%
  summarise(PriceSQmeter = mean(AvgSQmeter), UnemploymentRate = mean(Unemployment),POP = mean(POP))

# Create ggplot
ggp <- ggplot(merged_data, aes(x = PriceSQmeter, y = UnemploymentRate, color = POP, text = paste("DEP:", DEPARTEMENT))) +
  scale_color_gradient(low = "blue", high = "green") +
  geom_point(size = 3) +
  labs(title = "Comparison between Unemployment rate and M² price (2014-2021)",
       x = "Average M² Price",
       y = "Unemployment rate") +
  theme_minimal()

# Convert ggplot to plotly
p <- ggplotly(ggp, height = 400, width = 700)

# Customize layout if needed
p
```

The scatter plot indicates that departments with lower real estate costs per square meter tend to have smaller populations and higher rates of unemployment.
This trend may reflect economic vitality in more densely populated areas, likely due to a variety of employment opportunities and more robust economic activities.
In contrast, areas with less population may offer fewer job opportunities, contributing to higher unemployment rates and lower housing costs due to lower demand.

The visualization of data thus leads us to a plausible hypothesis: individuals may be inclined to move towards more populous regions when seeking work, driven by the promise of a more favorable job market.

#### Unemployment heatmap

```{r, echo = TRUE, message = FALSE, warning = FALSE}
# Read data
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

# Filter and aggregate data
df <- data %>%
  filter(Year >= 2016 & Year <= 2021) %>%
  group_by(Year, Group) %>%
  summarise(UnemploymentRate = mean(Unemployment))

# Create ggplot heatmap
gg_heatmap <- ggplot(df, aes(x = Year, y = Group, fill = UnemploymentRate)) +
  geom_tile() +
  scale_fill_gradientn(colors = brewer.pal(9, "Purples"), name = "UnemploymentRate") +
  labs(title = "UnemploymentRate Heatmap", x = "Year", y = "Group") +
  theme_minimal()

# Convert ggplot to Plotly
heatmap_plot <- ggplotly(gg_heatmap, height = 400, width = 700)

# Display the plot
heatmap_plot
```

The heat map shows the evolution of unemployment rates for four groups of départements ranked by population from 2016 to 2021 The shades of color vary from light to dark indicating unemployment rates of 8 to 10%.
The darker the color, the higher the unemployment rate.
Groups of departments with larger populations could be those with darker shades suggesting higher unemployment rates.
This could indicate economic challenges specific to more populated areas, or labor market dynamics that vary according to population density.
The general trend or significant changes over the years could reflect the impact of major economic events or employment policies on different types of departments.

## 3.5 Inflation, Interest Rate & PIB

```{r, echo = TRUE, message = FALSE, warning = FALSE, out.width='100%'}
library(ggplot2)

data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(InterestRate = mean(interest_rate), Inflation = mean(tx_inflation), GDP = mean(PIB))

# Create a plot of interest rate and inflation over the years with lines and points
interet <- ggplot(new_data, aes(x = Year)) +
  geom_line(aes(y = InterestRate, color = "Interest Rate"), linetype = "solid") +
  geom_point(aes(y = InterestRate, color = "Interest Rate")) +
  
  geom_line(aes(y = Inflation, color = "Inflation"), linetype = "dashed") +
  geom_point(aes(y = Inflation, color = "Inflation")) +
  
  geom_line(aes(y = GDP, color = "GDP"), linetype = "solid") +
  geom_point(aes(y = GDP, color = "GDP")) +
  
  geom_bar(aes(x = Year, y = Inflation), stat = "identity", fill = "orange", alpha = 0.5) +
  geom_bar(aes(x = Year, y = InterestRate), stat = "identity", fill = "blue", alpha = 0.5) +
  geom_bar(aes(x = Year, y = GDP), stat = "identity", fill = "black", alpha = 0.5) +
  
  labs(title = "Interest Rate, Inflation & GDP Over the Years",
       x = "Year",
       y = "Value") +
  theme_minimal() +
  scale_color_manual(values = c("Interest Rate" = "blue", "Inflation" = "orange", "GDP" = "black"), 
                     name = "Legend Title")

# Show the plot
print(interet)
```

The graph show how these macroeconomic indicators have moved over the years, which can be important for analyzing economic health, setting monetary policy, and understanding market trends.
We can observe here a falling trend of every macroeconomic factors during covid-19 pandemic and a raise of variables.

## 3.7 Multipanel variables

#### Panel

```{r, echo = TRUE, message = FALSE, warning = FALSE, out.width='80%'}
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2014 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(Year) %>%
  summarise(pop = sum(POP), sales = sum(Nb_sales), price =  mean(AvgSQmeter),surface = mean(Surface), crime = mean(criminality), chomage = mean(Unemployment),
           interest =  mean(interest_rate), inflation = mean(tx_inflation), PIB = mean(PIB) )

# Assuming your dataset is named 'new_data'

# Melt the data to long format
new_data_long <- new_data %>%
  gather(variable, value, -Year)

# Create a facet plot for each variable
facet_plot <- ggplot(new_data_long, aes(x = Year, y = value, color = variable)) +
  geom_line() +
  geom_point() +
  facet_wrap(~variable, scales = "free_y") +
  labs(title = "Multiple Variables by Year",
       x = "Year",
       y = "Value") +
  theme_minimal()

# Show the plot
print(facet_plot)
```

Here we have trends in selected variables over the period 2014 to 2021.
We can see that GDP, population, inflation, property prices, sales and area sold are all on the rise.
On the other hand, interest rates, crime and unemployment are falling.
We can hypothesize that there is a potential negative correlation between these variables, which we will study in greater depth during the analysis.

#### Correlation map with all the variables

```{r, echo = TRUE, warning = FALSE, message = FALSE, out.width='100%'}
data <- read.csv("~/MyDoc/University/Master/Management/DATA/FINAL_WORK/DSFBA/dataset_vf/PrixPopCrimeYearChomIntInf_vf4.csv")

filtered_data <- data %>%
  filter(Year >= 2016 & Year <= 2021)

# Group data by year and calculate population and total number of crimes
new_data <- filtered_data %>%
  group_by(DEPARTEMENT) %>%
  summarise(pop = mean(POP), sales = mean(Nb_sales), price =  mean(AvgSQmeter),surface = mean(Surface), criminality = mean(criminality), chomage = mean(Unemployment),
            interest =  mean(interest_rate), inflation = mean(tx_inflation),  PIB = mean(PIB))


cor_vars <- select_if(new_data, is.numeric)

# Calculate the correlation matrix
cor_matrix <- cor(cor_vars)

# Plot the correlation matrix using corrplot
corrplot(cor_matrix, method = "color", type = "upper", tl.cex = 0.8, tl.col = "black")
```

By creating a correlation graph of the selected variables, we can get a first idea of the potential correlations we may have.
For exemple,Red collor show a strong negative correlation, white is no correlation and dark blue for a strong positive correlation.
This graph should be read with caution, as we don't know whether the relationships are significant.
We will study all these correlations in greater depth in the analysis with more advanced statistical methods.
